---
title: "Stats2Project2"
author: "Aniketh V, Vijay Kaniti"
date: "7/22/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Load the libraries
```{r}
library(dplyr)
library(ggplot2)
library(tidyr)
library(magrittr)
library(stringr)
library(corrplot)
library(caret)
library(glmnet)
library(Lahman)
library(mice)
library(car)
library(MASS)
library(ROCR)
library(caret)
library(dplyr)
library(ggplot2)
library(tidyr)
library(readr)
library(digest)
library(ISLR)
library(car) 
library(leaps)
library(Matrix)
library(foreach)
library(glmnet)
library(VIM)
library(mice)
library(corrgram)
library(car)
library(gridExtra)
library(MASS)
library(mvtnorm)
library(class)
library(caret)
library(e1071)
library(class)
library(generalhoslem)
```

Loading dataset
```{r}
#imported the main data
Bank_Fix <- read.csv("bank-additional-full.csv",sep=";",header=TRUE, strip.white = TRUE, na.strings = c("unknown"))

#Separted the header string into separate columns
#Bank_Fix = mainBank %>% separate(age.job.marital.education.default.housing.loan.contact.month.day_of_week.duration.campaign.pdays.previous.poutcome.emp.var.rate.cons.price.idx.cons.conf.idx.euribor3m.nr.employed.y, c("age", "job", "marital", "education", "default", "housing", "loan", "contact", "month", "day_of_week", "duration", "campaign", "pdays", "previous", "poutcome", "emp.var.rate", "cons.price.idx", "cons.conf.idx", "euribor3m", "nr.employed", "y"), ";", extra = "merge")

Bank_Fix$age = as.integer(Bank_Fix$age)
Bank_Fix$nr.employed = as.integer(Bank_Fix$nr.employed)
Bank_Fix$euribor3m = as.double(Bank_Fix$euribor3m)
Bank_Fix$cons.conf.idx = as.double(Bank_Fix$cons.conf.idx)
Bank_Fix$cons.price.idx = as.double(Bank_Fix$cons.price.idx)
Bank_Fix$emp.var.rate = as.double(Bank_Fix$emp.var.rate)
Bank_Fix$previous = as.integer(Bank_Fix$previous)
Bank_Fix$pdays = as.integer(Bank_Fix$pdays)
Bank_Fix$campaign = as.integer(Bank_Fix$campaign)
Bank_Fix$duration = as.integer(Bank_Fix$duration)
Bank_Fix$y = as.factor(Bank_Fix$y)
Bank_Fix$poutcome = as.factor(Bank_Fix$poutcome)
Bank_Fix$term_deposit = Bank_Fix$y
Bank_Fix$default = as.factor(Bank_Fix$default)
Bank_Fix$housing = as.factor(Bank_Fix$housing)
Bank_Fix$marital = as.factor(Bank_Fix$marital)
Bank_Fix$loan = as.factor(Bank_Fix$loan)
Bank_Fix$job = as.factor(Bank_Fix$job)


for(i in 1 : nrow(Bank_Fix)){
  if (Bank_Fix$age[i] < 20){
    Bank_Fix$Agegroup[i] = 'Teenagers'
  } else if (Bank_Fix$age[i] < 35 & Bank_Fix$age[i] > 19){
    Bank_Fix$Agegroup[i] = 'Young Adults'
  } else if (Bank_Fix$age[i] < 60 & Bank_Fix$age[i] > 34){
    Bank_Fix$Agegroup[i] = 'Adults'
  } else if (Bank_Fix$age[i] > 59){
    Bank_Fix$Agegroup[i] = 'Senior Citizens'
  }
  
}
Bank_Fix$Agegroup<-as.factor(Bank_Fix$Agegroup)


Bank_Fix$y = NULL


#find out the data types
dplyr::glimpse(Bank_Fix)


#Imputed NA values
tempData <- mice(Bank_Fix,m=1,maxit=0,method ='logreg',seed=500)
Bank_Fix_Imp <- complete(tempData,1)

#Removing Outliers
Bank_Fix_Imp = Bank_Fix_Imp[-c(36044,40538,24092), ]
summary(Bank_Fix_Imp)
```

```{r}
#Some initial EDAs
summary(Bank_Fix_Imp)

#Split catergorical and continuous data
Bank_Conti <- Bank_Fix_Imp[, !sapply(Bank_Fix, is.factor)]
Bank_categ <- Bank_Fix_Imp[, sapply(Bank_Fix, is.factor)]
Bank_Conti <- Bank_Fix_Imp[, !sapply(Bank_Fix_Imp, is.factor)]
Bank_categ <- Bank_Fix_Imp[, sapply(Bank_Fix_Imp, is.factor)]


#Boxplots
boxplot(Bank_Conti$age)
boxplot(Bank_Conti$nr.employed)
boxplot(Bank_Conti[,2,3])

#ScatterPlot
pairs(Bank_Conti[,1:10], pch = 19)

```

```{r,EDA}
## Summary on Job variable, customers job status
summary(Bank_Fix_Imp$job)
catnames = names(Bank_Fix_Imp)[sapply(Bank_Fix_Imp, class) == "factor"]

Bank_Fix_Imp$term_deposit = as.factor(Bank_Fix_Imp$term_deposit)

spineplot(x = Bank_Fix_Imp$job, y = Bank_Fix_Imp$term_deposit, xlab = "Job", ylab = "y",
          main = "Job vs Y", col = c("lightblue", "coral"), xaxlabels = levels(Bank_Fix_Imp$job))
chisq.test(Bank_Fix_Imp$job, Bank_Fix_Imp$term_deposit)
#CrossTable(Bank_Fix_Imp$job, Bank_Fix_Imp$term_deposit)

##job is dependent on term_deposit
##marital is dependent on term_deposit

summary(Bank_Fix_Imp$marital)
chisq.test(Bank_Fix_Imp$marital, Bank_Fix_Imp$term_deposit)
#CrossTable(Bank_Fix_Imp$marital, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$education, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$default, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$housing, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$loan, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$contact, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$month, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$day_of_week, Bank_Fix_Imp$term_deposit)
chisq.test(Bank_Fix_Imp$poutcome, Bank_Fix_Imp$term_deposit)
#CrossTable(Bank_Fix_Imp$poutcome, Bank_Fix_Imp$term_deposit)
##marital is dependent on term_deposit
## contact has some difference in "yes" and "no" among its categories (cellular and telephone). cellular with 14.7% and 5.2% for "yes" rsponse
## P-value of  Chi-Square Test suggests that the variable "contact" has a  relationship with response variable. We can keep this variable for final analysis
## Day of the week has some difference in "yes" and "no" among its categories. Most of the calls were on Thursday (12.1%) and other days are close to 10% 
## P-value of  Chi-Square Test suggests that the variable "day_of_week" has a  relationship with response variable. We can keep this variable for final analysis
## 65.1% of customers where previous outcome was "Success" has a response of "yes"  
## 14.2% of customers where previous outcome was "failure" has a response of "yes"  
## 8.8% of customers who were not contacted has a response of "yes"  
## P-value of  Chi-Square Test suggests that the variable "poutcome" has a  relationship with response variable. We can keep this variable for final analysis

##### We need to keep below variables in the predictive model
## job   marital  education  contact  month  day_of_week  poutcome

##### Below variables will not be included in the predictive model as there is no significance with response variable
## default  housing  loan

#multicolliniarity check
bank.model<-lm(age~duration+campaign+pdays+previous+emp.var.rate+cons.price.idx+cons.conf.idx+euribor3m+nr.employed, data=Bank_Fix_Imp)
summary(bank.model)
vif(bank.model)
# removed varaible euribor3m which has VIF 63.51
bank.model1<-lm(age~duration+campaign+pdays+previous+emp.var.rate+cons.price.idx+cons.conf.idx+nr.employed, data=Bank_Fix_Imp)
summary(bank.model1)
vif(bank.model1)
#removed varaible emp.var.rate which has VIF 24.12
bank.model2<-lm(age~duration+campaign+pdays+previous+cons.price.idx+cons.conf.idx+nr.employed, data=Bank_Fix_Imp)
summary(bank.model2)
vif(bank.model2)

#### We can remove variables emp.var.rate and euribor3m as these variables are highly correlated with nr.employed
corrgram(Bank_Fix_Imp, order=TRUE,
         upper.panel=panel.cor, lower.panel=panel.pie, main="Bank data Correlogram")


## euribor3m and nr.employed are highly correlated (0.95)
## emp.var.rate and euribor3m are highly correlated (0.97)
## emp.var.rate and nr.employed are highly correlated (0.91)

summary(Bank_Fix_Imp$age)
Bank_Fix_Imp %>%  ggplot(aes(x = age, fill = term_deposit, color=term_deposit)) + geom_bar() + ggtitle("Distribution of Age") + xlab("Age") + 
  scale_x_continuous(breaks = seq(0, 100, 5))
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=age, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of Age") + xlab("Response") + ylab ("Age")


## The minimum and maximum values are 17 and 98 and distribution of age is slightly right screwed 
## Highest concentration of values between 22 and 60 and distribution of values between 22 and 60 is normal

## Summary on duration variable
summary(Bank_Fix_Imp$duration)
Bank_Fix_Imp %>%  ggplot(aes(x = duration, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of Duration") + xlab("Duration") +
  scale_x_continuous(breaks = seq(0, 5000, 300)) 
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=duration, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of Duration") + xlab("Response") + ylab ("Duration")


## The minimum and maximum values are 0 and 4918 sec and distribution of duration is highly right screwed 
## "duration" and "term_deposit"are pretty strongly associated. The longer duration is, the bigger prportion of people subscibe a term deposit.

## Summary on campaign variable. Number of contacts performed during this campaign and for this client 
# summary(Bank_Fix_Imp$campaign)
# Bank_Fix_Imp %>%  ggplot(aes(x = campaign, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of Campaign") + xlab("Campaign")+
#   scale_x_continuous(breaks = seq(0, 50, 1)) 
# ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=campaign, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of campaign") + xlab("Response") + ylab ("campaign")
# aggregate(data.frame(count = Bank_Fix_Imp$campaign), list(value = Bank_Fix_Imp$campaign), length)
# Bank_Fix_Imp <- Bank_Fix_Imp %>%   
#     filter(campaign <= 10) 


## The minimum and maximum values are 1 and 56 and distribution of campaign is right screwed 
## looks like outlier in capaign varaible, after 8, the outcome is "no" for all observations. we can limit our study to 8
## Most of the campaign is on 1 and 2.
## There is a trend that the more number of campaign, the less percentage of clients substribe a term deposit, Expecially for campaign more than 3.

## Summary on pdays variable. Number of days that passed by after the client was last contacted from a previous campaign
summary(Bank_Fix_Imp$pdays)
Bank_Fix_Imp %>%  ggplot(aes(x = pdays, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of pdays") + xlab("pdays") 
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=pdays, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of pdays") + xlab("Response") + ylab ("pdays")
aggregate(data.frame(count = Bank_Fix_Imp$pdays), list(value = Bank_Fix_Imp$pdays), length)

## most of the observations has value of 999 which mean these customers never contacted in the past.

## Summary on previous variable. How many number of contacts performed before this campaign 
summary(Bank_Fix_Imp$previous)
Bank_Fix_Imp %>%  ggplot(aes(x = previous, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of previous") + xlab("previous") 
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=previous, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of previous") + xlab("Response") + ylab ("previous")
aggregate(data.frame(count = Bank_Fix_Imp$previous), list(value = Bank_Fix_Imp$previous), length)

## The minimum and maximum values are 0 and 7. Most of the obserations with 0 value mean the customers never contacted in the past.

## Summary on emp.var.rate variable. We can remove this variable from our analysis because of multicolliniarity 
summary(Bank_Fix_Imp$emp.var.rate)
Bank_Fix_Imp %>%  ggplot(aes(x = emp.var.rate, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of emp.var.rate") + xlab("emp.var.rate") 
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=emp.var.rate, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of emp.var.rate") + xlab("Response") + ylab ("emp.var.rate")


## Summary on cons.price.idx variable. consumer price index - monthly indicator
summary(Bank_Fix_Imp$cons.price.idx)
Bank_Fix_Imp %>%  ggplot(aes(x = cons.price.idx, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of cons.price.idx") + xlab("cons.price.idx")
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=cons.price.idx, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of cons.price.idx") + xlab("Response") + ylab ("cons.price.idx")

## Overall, comsumer price index has some difference in "yes" and "no" among different values
## Minimum and maximum values are 92.20 and 94.77 respectively

## Summary on cons.conf.idx variable. consumer confidence index - monthly indicator 
summary(Bank_Fix_Imp$cons.conf.idx)
Bank_Fix_Imp %>%  ggplot(aes(x = cons.conf.idx, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of cons.conf.idx") + xlab("cons.conf.idx")
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=cons.conf.idx, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of cons.conf.idx") + xlab("Response") + ylab ("cons.conf.idx")

## Overall, comsumer confidence index has some difference in "yes" and "no" among different values
## Minimum and maximum values are -50.8 and -26.9 respectively


## Summary on euribor3m variable. euribor 3 month rate - daily indicator 
summary(Bank_Fix_Imp$euribor3m)
Bank_Fix_Imp %>%  ggplot(aes(x = euribor3m, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of euribor3m") + xlab("euribor3m")
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=euribor3m, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of euribor3m") + xlab("Response") + ylab ("euribor3m")


## Minimum and maximum values are 0.634 and 5.045 respectively

## Summary on nr.employed variable. We can remove this variable from our analysis because of multicolliniarity 
summary(Bank_Fix_Imp$nr.employed)
Bank_Fix_Imp %>%  ggplot(aes(x = nr.employed, fill = term_deposit)) + geom_bar() + ggtitle("Distribution of nr.employed") + xlab("nr.employed")
ggplot(Bank_Fix_Imp, aes(x = term_deposit, y=nr.employed, fill=term_deposit)) + geom_boxplot() + ggtitle("Distribution of nr.employed") + xlab("Response") + ylab ("nr.employed")

### Delete variables which are multicollinear and correlated

##### Below variables will not be included in the predictive model as there is no significance with response variable 
## default  housing  loan

###Remove emp.var.rate and nr.employed -multicollinear
View (Bank_Fix_Imp)

Bank_Fix_Imp$default <- Bank_Fix_Imp$housing <- Bank_Fix_Imp$loan <- NULL

Bank_Fix_Imp$emp.var.rate <- Bank_Fix_Imp$nr.employed <- NULL



```

```{r, split}
#Training and Test from imputed data
set.seed(100)
split_percent = .70
trainIndices = sample(1:dim(Bank_Fix_Imp)[1],round(split_percent * dim(Bank_Fix_Imp)[1]))
train = Bank_Fix_Imp[trainIndices,]
test = Bank_Fix_Imp[-trainIndices,]
summary(train)
table(train$term_deposit)

#Downsampling to make a better distribution of yes and no. Used the smote function for the downsampling to make it better

#set.seed(1000)
#down_train <- downSample(x = train[, -ncol(train)],
#                         y = train$term_deposit)
#table(down_train$Class)

library(DMwR)
set.seed(9560)
smote_train <- SMOTE(term_deposit ~ ., data  = train)                         
table(smote_train$term_deposit)

```

####PCA and LDA

```{r}
Bank_Fix_Imp_Numeric <- cbind(Bank_Fix_Imp[,11:14],Bank_Fix_Imp[,16:20])

pc.result<-prcomp(Bank_Fix_Imp_Numeric,scale=FALSE)
pc.scores<-pc.result$x
cor(pc.scores)
par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:7,eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:7,cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))
par(mfrow=c(1,1))
summary(pc.result)

##PC3 shows 99.99 cummulative proportion
#Adding the response column to the PC's data frame
pc.scores<-data.frame(pc.scores)
pc.scores$y<-Bank_Fix_Imp$term_deposit

#Use ggplot2 to plot the first few pc's
library(ggplot2)
ggplot(data = pc.scores, aes(x = PC1, y = PC2)) +
geom_point(aes(col=y), size=1)+  ggtitle("PCA of Responses")

loadinscores<-pc.result$rotation[,1]
var_scores<-abs(loadinscores)
var_scores_ranked<-sort(var_scores,decreasing = TRUE)
var_scores_ranked

library(ROCR)
library(MASS)
mylda<- lda(term_deposit ~ duration+campaign+euribor3m+nr.employed+cons.price.idx+cons.conf.idx, data = smote_train)
##myqda<- qda(term_deposit ~  duration+pdays+campaign+euribor3m, data = Bank_Fix_Imp)

#confusion matrix and accuracy
prd<-predict(mylda, newdata = test)$class
table(prd,test$term_deposit)
mean(prd==test$term_deposit)

#For ROC curves
my.prd = predict(mylda, newdata = test)
#ROC Curve
prediction(my.prd$posterior[,2], test$term_deposit) %>%
  performance(measure = "tpr", x.measure = "fpr") %>%
  plot() %>% title("ROC Graph for LDA Model")
#AUC
prediction(my.prd$posterior[,2], test$term_deposit) %>%
  performance(measure = "auc") %>%
  .@y.values

#Overall Misclassification Error rate on the test is 
##Accuracy (all correct / all) = TP + TN / TP + TN + FP + FN
##Misclassification (all incorrect / all) = FP + FN / TP + TN + FP + FN
# prd      no   yes
##no  35306  2710
##yes  1242  1930
##37236/41188=90.4%
```

All Models and Prediction
```{r}
#Simple Model
simple.log = glm(term_deposit ~ Agegroup + job + marital + education + contact + month + day_of_week + poutcome + campaign + duration + pdays + previous + cons.price.idx + cons.conf.idx, family = "binomial", data = smote_train)
summary(simple.log)
exp(cbind("Odds ratio" = coef(simple.log), confint.default(simple.log, level = 0.95)))

#pdays

#Testing the complex logistic model with different predictors as achieved from the EDA
simple.final.log = glm(term_deposit ~ job + Agegroup + marital + education + contact + month + day_of_week + poutcome + duration*poutcome + cons.price.idx*cons.conf.idx + Agegroup*marital, data = smote_train, family = "binomial")
summary(simple.final.log)

#nr.employed + cons.price.idx*cons.conf.idx

#smote Train data  step wise
full.log = glm(term_deposit ~ ., family = "binomial", data = smote_train)
step.log = full.log %>% stepAIC(trace=FALSE)
summary(step.log)
exp(cbind("Odds ratio" = coef(step.log), confint.default(step.log, level = 0.95)))
vif(step.log)

#smote Train data lasso 
dat.train.x <- model.matrix(term_deposit ~ ., smote_train)[,-1]
dat.train.y<-smote_train$term_deposit
cvfit <- cv.glmnet(dat.train.x, dat.train.y, family = "binomial", type.measure = "class", nlambda = 1000)
plot(cvfit)
coef(cvfit, s = "lambda.min")

#final lasso model
finalLassoModel<-glmnet(dat.train.x, dat.train.y, family = "binomial",lambda=cvfit$lambda.min)
cvfit$lambda.min

tLL = finalLassoModel$nulldev - deviance(finalLassoModel)
k = finalLassoModel$df
n = finalLassoModel$nobs
AICc = -tLL+2*k*2*k*(k+1)/(n-k-1)

##performing prediction using both models
dat.test.x<-model.matrix(term_deposit ~ ., test)[,-1]
fit.pred.lasso <- predict(finalLassoModel, newx = dat.test.x, type = "response")
fit.pred.step<-predict(step.log,newdata=test,type="response")
fit.pred.final <- predict(simple.final.log, newdata = test, type = "response")
fit.pred.simple <- predict(simple.log, newdata = test, type = "response")

##Error rate simple model
mean(ifelse(fit.pred.simple > 0.5, "yes", "no") != test$term_deposit)
#Error Rate for complex model
mean(ifelse(fit.pred.final > 0.5, "yes", "no") != test$term_deposit)
#Error Rate for stepwise model
mean(ifelse(fit.pred.step > 0.5, "yes", "no") != test$term_deposit)
#Error rate for lasso model
mean(ifelse(fit.pred.lasso > 0.5, "yes", "no") != test$term_deposit)


cutoff<-0.5
class.lasso<-factor(ifelse(fit.pred.lasso>cutoff,"yes","no"),levels=c("no","yes"))
class.step<-factor(ifelse(fit.pred.step>cutoff,"yes","no"),levels=c("no","yes"))
class.simple<-factor(ifelse(fit.pred.simple>cutoff,"yes","no"),levels=c("no","yes"))
class.simpleFinal<-factor(ifelse(fit.pred.final>cutoff,"yes","no"),levels=c("no","yes"))

#Confusion Matrix for Lasso
conf.lasso<-table(class.lasso,test$term_deposit)
print("Confusion matrix for LASSO")
## [1] "Confusion matrix for LASSO"
conf.lasso

#Confusion Matrix for Stepwise
conf.step<-table(class.step,test$term_deposit)
print("Confusion matrix for Stepwise")
## [1] "Confusion matrix for Stepwise"
conf.step

#Confusion Matrix for Simple model
conf.simple = table(class.simple, test$term_deposit)
print("Confusion Matrix for Simple")
conf.simple

#Confusion Matrix for Simple model
conf.final = table(class.simpleFinal, test$term_deposit)
print("Confusion Matrix for Simple Final")
conf.final

#Confusion Matrix for Simple complex
sum(diag(conf.lasso))/sum(conf.lasso)
sum(diag(conf.step))/sum(conf.step)
sum(diag(conf.simple))/sum(conf.simple)
sum(diag(conf.final))/sum(conf.final)


#Lasso ROC Curve
results.lasso<-prediction(fit.pred.lasso, test$term_deposit)
roc.lasso = performance(results.lasso, measure = "tpr", x.measure = "fpr")
plot(roc.lasso,colorize = TRUE)
abline(a=0, b= 1)

#stepwise ROC Curve
results.step = prediction(fit.pred.step, test$term_deposit, label.ordering = c("no","yes"))
roc.step = performance(results.step, measure = "tpr", x.measure = "fpr")

#simple model
results.simple = prediction(fit.pred.simple, test$term_deposit, label.ordering = c("no", "yes"))
roc.simple = performance(results.simple, measure = "tpr", x.measure = "fpr")

#Complex model
result.final = prediction(fit.pred.final, test$term_deposit, label.ordering = c("no", "yes"))
roc.final = performance(result.final, measure = "tpr", x.measure = "fpr")

#Plot stepwise, Lasso, and gen simple model
plot(roc.lasso)
plot(roc.step, col = "orange", add = TRUE)
plot(roc.simple, col = "blue", add = TRUE)
plot(roc.final, col = "red", add = TRUE)
legend("bottomright",legend=c("Lasso","Stepwise","Simple Model Only", "Complex Model"),col=c("black","orange","blue", "red"),lty=1,lwd=1)
abline(a=0, b= 1)

#AUC Stepwise
auc.tmp.step = performance(results.step, "auc")
auc.step = as.numeric(auc.tmp.step@y.values)
auc.step

#AUC Lasso
auc.tmp.lasso = performance(results.lasso, "auc")
auc.lasso = as.numeric(auc.tmp.lasso@y.values)
auc.lasso

#AUC Simple
auc.tmp.simple = performance(results.simple, "auc")
auc.simple = as.numeric(auc.tmp.simple@y.values)
auc.simple

#AUC for Complex
auc.tmp.compex = performance(result.final, "auc")
auc.complex = as.numeric(auc.tmp.compex@y.values)
auc.complex

#AUC for the LDA
auc.tmp.lda = performance(prd, "auc")
auc.lda = as.numeric(auc.tmp.lda)
auc.lda
```


```{r}
#Random Forest attempt
bag.adv<-randomForest(term_deposit ~ job + marital + education + contact + month + day_of_week + poutcome + cons.price.idx:cons.conf.idx,data=smote_train,
                       mtry=2,importance =TRUE,ntree=100)

yhat.bag = predict(bag.adv, newdata=test)
plot(yhat.bag, test$term_deposit,main="Bagged Model",xlab="Predicted",ylab="Test Set term")
abline (0,1)

library(tree)
mytree<-tree(term_deposit ~ job + marital + education + contact + month + day_of_week + poutcome + cons.price.idx,smote_train)
yhat.tree<-predict(mytree,newdata=test)
plot(yhat.tree,test$sales,main="Single Tree with 8 splits",xlab="Predicted",ylab="Test Set Term")
abline(0,1)

mytree<-tree(term_deposit ~ job + marital + education + contact + month + day_of_week + poutcome + cons.price.idx,smote_train,minsize=8,mindev=.0001)
yhat.tree<-predict(mytree,newdata=test)
plot(yhat.tree,test$sales,main="Single Tree with Deep Splits",xlab="Predicted",ylab="Test Set Term")
abline(0,1)


#Lets take a look at the predicted surface of our bagged model
predictors<-data.frame(TV=rep(0:300,51),radio=rep(0:50,each=301))
bag.full<-randomForest( sales ~ TV+radio,data=Adver , subset=index ,
                        mtry=2,importance =TRUE,ntree=100)

pred.surface<-matrix(predict(bag.full,predictors),301,51)
plot3d(TV,radio,sales)
surface3d(0:300,0:50,pred.surface,alpha=.4)

# Train model with knn and get importance of predictors
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(100)
model.knn <- train(term_deposit ~ ., data=Bank_Fix_Imp[,-c(2)], method="knn", trControl=control)
#Top 10 predictor ranking
importance.knn <- varImp(model.knn, scale=FALSE)
rank.knn <- importance.knn$importance
write.csv(rank.knn, "rank.knn.csv")
rank.knn <- read.csv("rank.knn.csv", header=TRUE)
colnames(rank.knn) <- c("Predictors", "Importance")
rank.knn <- rank.knn[order(rank.knn$Importance, decreasing = TRUE),]
ggplot(rank.knn[1:20,], aes(x=reorder(Predictors, Importance),y=Importance)) + geom_bar(stat = "identity") + coord_flip() + labs(title="Importance of Predictors", x="Predictors", y="Importance") +theme(axis.text.x=element_text(hjust=0.5, vjust=0.5, size = 12))+theme(axis.text.y=element_text(size = 12))

#KNN including all continuous predictors for model performance
set.seed(100)
iterations = 5
numks = 30
splitPerc = .70
kkk = c()
Sens = c()
Spec = c()
masterAcc = matrix(nrow = iterations, ncol = numks)
for(j in 1:iterations)
{
   trainIndices = sample(1:dim(Bank_Fix_Imp)[1],round(splitPerc * dim(Bank_Fix_Imp)[1]))
    train = Bank_Fix_Imp[trainIndices,]
    test = Bank_Fix_Imp[-trainIndices,]
    smote_train <- SMOTE(term_deposit ~ ., data  = train)                         
  for(i in 1:numks)
  {
    classifications = knn(smote_train[,c(1,11,12,13,14,16,17,18,19,20)],test[,c(1,11,12,13,14,16,17,18,19,20)],smote_train$term_deposit, prob = TRUE, k = i)
    u <- union(classifications,test$term_deposit)
    t <- table(factor(classifications, u), factor(test$term_deposit, u))
    CM = confusionMatrix(t)
    masterAcc[j,i] = CM$overall[1]
    kkk[i] = CM$overall[1]
    Sens[i] = CM$byClass[1]
    Spec[i] = CM$byClass[2]
  }
}
MeanAcc = colMeans(masterAcc)
plot(seq(1,numks,1),MeanAcc, type = "l")
combo = data.frame(k = 1:30, Sensitivity = Sens, Specificity = Spec, MeanAcc)
which.max(MeanAcc)
max(MeanAcc)
mean(combo$Sensitivity)
mean(combo$Specificity)
```














